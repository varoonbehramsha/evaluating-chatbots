{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "You will need the following begore you begin:\n",
        "1. An Excel file (Google Sheet) with questions, context and responses from the Chatbot being evaluated, stored in your Google Drive.\n",
        "2. An [OpenAI API Key](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key), added as a Secret named 'OPENAI_API_KEY' on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP9tXZZRsmKp"
      },
      "source": [
        "## Install Uptrain package\n",
        "https://github.com/uptrain-ai/uptrain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpA30YzDGiJ3"
      },
      "outputs": [],
      "source": [
        "pip install uptrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COVDG4zGGiJ5"
      },
      "outputs": [],
      "source": [
        "pip install rouge_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlkTl5Jhw77L"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o2WTOxgOL-Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmWMdCf9GiJ5"
      },
      "source": [
        "## Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqxVV32aGiJ6"
      },
      "outputs": [],
      "source": [
        "from uptrain import EvalLLM, Evals, CritiqueTone, ResponseMatching\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "import openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract Data from Excel File\n",
        "Extract the data from the Google Sheet into a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhwiXlsTGiJ6"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/My Drive/LLM Evaluations/lh_test_data_with_response.xlsx'. #\n",
        "# Read the Excel file into a pandas DataFrame\n",
        "df = pd.read_excel(file_path, engine='openpyxl')\n",
        "# Create a dictionary containing records from the excel file\n",
        "faqs = df.to_dict(orient='records')\n",
        "print(faqs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDswNS58xsHu"
      },
      "source": [
        "## Evaluate\n",
        "Evaluate the chatbot responses for factual accuracy and response relevance using Uptrain + GPT 3.5 Turbo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLdT4tGOGiJ6"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "eval_llm = EvalLLM(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "results = eval_llm.evaluate(\n",
        "          data=faqs,\n",
        "          checks=[Evals.FACTUAL_ACCURACY, Evals.RESPONSE_RELEVANCE]\n",
        "        )\n",
        "\n",
        "json_data = json.dumps(results, indent=3)\n",
        "print(json_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWLyeyWezCBP"
      },
      "source": [
        "## Save results in an Excel file on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zwu9IcOGiJ7"
      },
      "outputs": [],
      "source": [
        "output_file_path = '/content/drive/My Drive/LLM Evaluations/llm_eval_results.xlsx'\n",
        "df = pd.DataFrame(results)\n",
        "df.to_excel(output_file_path, index=False, engine='openpyxl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
